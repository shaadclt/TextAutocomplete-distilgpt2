# Text Autocompletion with DistilGPT-2

This repository contains the code and resources for implementing text autocompletion using the DistilGPT-2 model from Hugging Face within a Jupyter Notebook environment.

## Overview

Text autocompletion is a powerful feature that assists users in writing by suggesting completions for partially entered text. Leveraging the capabilities of large language models like DistilGPT-2, this project aims to provide accurate and contextually relevant text suggestions for various applications such as code writing, content generation, and more.

## Features

- Utilizes the DistilGPT-2 model from Hugging Face for text autocompletion.
- Customizable parameters for generating text suggestions.
- Support for different programming languages and textual contexts.
- Seamless integration with Jupyter Notebook for interactive usage and experimentation.

## Requirements

- Python 3.9
- Jupyter Notebook
- Transformers library from Hugging Face

## Installation

1. Clone this repository to your local machine:
```bash
git clone https://github.com/shaadclt/Text-Autocompletion-distilgpt2.git
```

## Usage

1. Open the Jupyter Notebook provided **autocomplete_distilgpt2.ipynb** in your Jupyter environment.
2. Follow the instructions and code examples to experiment with text autocompletion using the DistilGPT-2 model.
3. Customize the prompts and parameters to generate text suggestions tailored to your specific needs.

## Contributing
Contributions are welcome! If you find any bugs or have suggestions for improvements, feel free to open an issue or submit a pull request.

## License
This project is licensed under the MIT License - see the LICENSE file for details.
